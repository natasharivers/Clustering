{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mall Customers Exercises\n",
    "\n",
    "## notebook\n",
    "\n",
    "1. Acquire data from mall_customers.customers in mysql database.\n",
    "2. Summarize data (include distributions and descriptive statistics).\n",
    "3. Detect outliers using IQR.\n",
    "4. Split data (train, validate, and test split).\n",
    "5. Encode categorical columns using a one hot encoder (pd.get_dummies).\n",
    "6. Handles missing values.\n",
    "7. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrangle_mall.py\n",
    "\n",
    "1. Acquire data from mall_customers.customers in mysql database.\n",
    "2. Split the data into train, validate, and split\n",
    "3. One-hot-encoding (pd.get_dummies)\n",
    "4. Missing values\n",
    "5. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pydataset import data\n",
    "import scipy.stats as stats\n",
    "import wrangle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# acquire\n",
    "from env import host, user, password\n",
    "import acquire\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1 Acquire data from mall_customers.customers in mysql database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function in acquire.py\n",
    "def get_connection(db_name):\n",
    "    '''\n",
    "    This function uses my info from my env file to\n",
    "    create a connection url to access the Codeup db.\n",
    "    '''\n",
    "    from env import host, user, password\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function in acquire.py\n",
    "def get_mall_customers():\n",
    "    '''\n",
    "    This function reads in the mall_customers data from the Codeup db\n",
    "    returns: a pandas DataFrame \n",
    "    '''\n",
    "    \n",
    "    mall_query = '''\n",
    "    SELECT *\n",
    "    FROM customers\n",
    "    '''\n",
    "    return pd.read_sql(mall_query, get_connection('mall_customers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_mall_customers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>spending_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gender  age  annual_income  spending_score\n",
       "customer_id                                            \n",
       "1              Male   19             15              39\n",
       "2              Male   21             15              81\n",
       "3            Female   20             16               6\n",
       "4            Female   23             16              77\n",
       "5            Female   31             17              40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2 Summarize data (include distributions and descriptive statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df):\n",
    "    '''\n",
    "    this function will take in a single argument (a pandas df) \n",
    "    output to console various statistics on said dataframe, including:\n",
    "    #.head()\n",
    "    #.info()\n",
    "    #.describe()\n",
    "    #.value_counts()\n",
    "    #observation of nulls in the dataframe\n",
    "    '''\n",
    "    #print head\n",
    "    print('=================================================')\n",
    "    print('Dataframe head: ')\n",
    "    print(df.head(3))\n",
    "    \n",
    "    #print info\n",
    "    print('=================================================')\n",
    "    print('Dataframe info: ')\n",
    "    print(df.info())\n",
    "    \n",
    "    #print descriptive stats\n",
    "    print('=================================================')\n",
    "    print('DataFrame Description')\n",
    "    print(df.describe())\n",
    "    num_cols = df.select_dtypes(exclude='O').columns.to_list()\n",
    "    cat_cols = df.select_dtypes(include='O').columns.to_list()\n",
    "    \n",
    "    #print value counts\n",
    "    print('=================================================')\n",
    "    print('Dataframe value counts: ')\n",
    "    for col in df. columns:\n",
    "        if col in cat_cols:\n",
    "            print(df[col].value_counts())\n",
    "        else:\n",
    "            print(df[col].value_counts(bins=10, sort = False))\n",
    "    \n",
    "    #print nulls by column\n",
    "    print('=================================================')\n",
    "    print('nulls in dataframe by column: ')\n",
    "    print(nulls_by_col(df))\n",
    "    \n",
    "    #print nulls by column\n",
    "    print('=================================================')\n",
    "    print('nulls in dataframe by row: ')\n",
    "    print(nulls_by_row(df))\n",
    "    print('=================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Dataframe head: \n",
      "             gender  age  annual_income  spending_score\n",
      "customer_id                                            \n",
      "1              Male   19             15              39\n",
      "2              Male   21             15              81\n",
      "3            Female   20             16               6\n",
      "=================================================\n",
      "Dataframe info: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 1 to 200\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   gender          200 non-null    object\n",
      " 1   age             200 non-null    int64 \n",
      " 2   annual_income   200 non-null    int64 \n",
      " 3   spending_score  200 non-null    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 7.8+ KB\n",
      "None\n",
      "=================================================\n",
      "DataFrame Description\n",
      "              age  annual_income  spending_score\n",
      "count  200.000000     200.000000      200.000000\n",
      "mean    38.850000      60.560000       50.200000\n",
      "std     13.969007      26.264721       25.823522\n",
      "min     18.000000      15.000000        1.000000\n",
      "25%     28.750000      41.500000       34.750000\n",
      "50%     36.000000      61.500000       50.000000\n",
      "75%     49.000000      78.000000       73.000000\n",
      "max     70.000000     137.000000       99.000000\n",
      "=================================================\n",
      "Dataframe value counts: \n",
      "Female    112\n",
      "Male       88\n",
      "Name: gender, dtype: int64\n",
      "(17.947, 23.2]    31\n",
      "(23.2, 28.4]      19\n",
      "(28.4, 33.6]      34\n",
      "(33.6, 38.8]      29\n",
      "(38.8, 44.0]      18\n",
      "(44.0, 49.2]      24\n",
      "(49.2, 54.4]      15\n",
      "(54.4, 59.6]      10\n",
      "(59.6, 64.8]       6\n",
      "(64.8, 70.0]      14\n",
      "Name: age, dtype: int64\n",
      "(14.877, 27.2]    24\n",
      "(27.2, 39.4]      22\n",
      "(39.4, 51.6]      28\n",
      "(51.6, 63.8]      38\n",
      "(63.8, 76.0]      32\n",
      "(76.0, 88.2]      34\n",
      "(88.2, 100.4]      8\n",
      "(100.4, 112.6]     6\n",
      "(112.6, 124.8]     4\n",
      "(124.8, 137.0]     4\n",
      "Name: annual_income, dtype: int64\n",
      "(0.901, 10.8]    16\n",
      "(10.8, 20.6]     20\n",
      "(20.6, 30.4]     10\n",
      "(30.4, 40.2]     17\n",
      "(40.2, 50.0]     40\n",
      "(50.0, 59.8]     32\n",
      "(59.8, 69.6]     11\n",
      "(69.6, 79.4]     24\n",
      "(79.4, 89.2]     14\n",
      "(89.2, 99.0]     16\n",
      "Name: spending_score, dtype: int64\n",
      "=================================================\n",
      "nulls in dataframe by column: \n",
      "                num_rows_missing  pct_rows_missing\n",
      "gender                         0               0.0\n",
      "age                            0               0.0\n",
      "annual_income                  0               0.0\n",
      "spending_score                 0               0.0\n",
      "=================================================\n",
      "nulls in dataframe by row: \n",
      "  num_cols_missing pct_cols_missing  customer_id\n",
      "0                0              0.0          200\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "df = wrangle.summarize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #3 Detect outliers using IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, k, col_list):\n",
    "    ''' \n",
    "    get upper and lower bound for list of columns in a dataframe \n",
    "    if desired return that dataframe with the outliers removed\n",
    "    '''\n",
    "    \n",
    "    odf = pd.DataFrame()\n",
    "    \n",
    "    for col in col_list:\n",
    "        \n",
    "        # get quartiles\n",
    "        q1, q2, q3 = df[f'{col}'].quantile([.25, .5, .75])  \n",
    "        \n",
    "        # calculate interquartile range\n",
    "        iqr = q3 - q1   \n",
    "        \n",
    "        # get upper bound\n",
    "        upper_bound = q3 + k * iqr\n",
    "        # get lower bound\n",
    "        lower_bound = q1 - k * iqr   \n",
    "        \n",
    "        # print each col and upper and lower bound for each column\n",
    "        print(f\"{col}: Median = {q2} lower_bound = {lower_bound} upper_bound = {upper_bound}\")\n",
    "\n",
    "        # return dataframe of outliers\n",
    "        odf = odf.append(df[(df[f'{col}'] < lower_bound) | (df[f'{col}'] > upper_bound)])\n",
    "            \n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b4f52f4d19dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0modf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annual_income'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spending_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-deb942cee949>\u001b[0m in \u001b[0;36mdetect_outliers\u001b[0;34m(df, k, col_list)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# get quartiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{col}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# calculate interquartile range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "odf = detect_outliers(df, 1.5,['age', 'annual_income', 'spending_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #4 Split data (train, validate, and test split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function from wrangle.py\n",
    "def zillow_split(df, target):\n",
    "    '''\n",
    "    This function take in get_zillow  from aquire.py and performs a train, validate, test split\n",
    "    Returns train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "    and prints out the shape of train, validate, test\n",
    "    '''\n",
    "    #create train_validate and test datasets\n",
    "    train, test = train_test_split(df, train_size = 0.8, random_state = 123)\n",
    "    #create train and validate datasets\n",
    "    train, validate = train_test_split(train, train_size = 0.7, random_state = 123)\n",
    "\n",
    "    #Split into X and y\n",
    "    X_train = train.drop(columns=[target])\n",
    "    y_train = train[target]\n",
    "\n",
    "    X_validate = validate.drop(columns=[target])\n",
    "    y_validate = validate[target]\n",
    "\n",
    "    X_test = test.drop(columns=[target])\n",
    "    y_test = test[target]\n",
    "\n",
    "    # Have function print datasets shape\n",
    "    print(f'train -> {train.shape}')\n",
    "    print(f'validate -> {validate.shape}')\n",
    "    print(f'test -> {test.shape}')\n",
    "   \n",
    "    return train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7579991907f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzillow_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logerror'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codeup-data-science/database-exercises/Clustering/wrangle.py\u001b[0m in \u001b[0;36mzillow_split\u001b[0;34m(df, target)\u001b[0m\n\u001b[1;32m    143\u001b[0m     '''\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m#create train_validate and test datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;31m#create train and validate datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2127\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2130\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[1;32m   2131\u001b[0m                                               default_test_size=0.25)\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "train, validate, test = wrangle.zillow_split(df, 'logerror')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #5 Encode categorical columns using a one hot encoder (pd.get_dummies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #6 Handles missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #7 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use min_max_scaler\n",
    "#age, income, spending score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
